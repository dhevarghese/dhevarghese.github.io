---
layout: about
title: about
permalink: /
subtitle: AI Researcher, VIS Lab

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >
    

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---

I'm currently working on combining discrete diffusion and autoregression for multilingual multimodal models with [Mohammad Mahdi Derakhshani](https://scholar.google.com/citations?user=n7GnOJoAAAAJ&hl=en) and [Cees Sneok](https://scholar.google.nl/citations?user=0uKdbscAAAAJ&hl=en) at the [VIS lab](https://ivi.fnwi.uva.nl/vislab/). Previously, for my thesis, I explored curriculum learning in Visual Language Models, supervised by [Yuki Asano](https://scholar.google.co.uk/citations?user=CdpLhlgAAAAJ&hl=en).

My experience with multimodality has made me curious to explore a few roads to improve efficiency in current models. I'd love to explore _'Long context adaptation'_ as a means to bring test and train closer; briding the gap and reducing the computational overhead of transformers. Also, I find hippocampal-cortical interactions very interesting üßê

[//]: # Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.
[//]: # <p>555 your office number</p>
[//]: # <p>123 your address street</p>
[//]: # <p>Your City, State 12345</p>
[//]: # drawing inspiration from neuroscience?
[//]: # Or in other words; I aim to improve the efficiency of transformers.
